@article{10.5555/972470.972475,
author = {Marcus, Mitchell P. and Marcinkiewicz, Mary Ann and Santorini, Beatrice},
title = {Building a Large Annotated Corpus of English: The Penn Treebank},
year = {1993},
issue_date = {June 1993},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
volume = {19},
number = {2},
issn = {0891-2017},
journal = {Comput. Linguist.},
month = {jun},
pages = {313–330},
numpages = {18}
}
@inproceedings{mikolovRecurrentNeuralNetwork2010a,
  title = {Recurrent Neural Network Based Language Model.},
  booktitle = {In {{INTERSPEECH}} 2010,},
  author = {Mikolov, Tomáš and Karafiát, Martin and Burget, Lukáš and {Jan} and Černocký, Honza " and Khudanpur, Sanjeev},
  date = {2010},
  pages = {1045--1048},
  abstract = {Abstract A new recurrent neural network based language model (RNN LM) with applications to speech recognition is presented. Results indicate that it is possible to obtain around 50\% reduction of perplexity by using mixture of several RNN LMs, compared to a state of the art backoff language model. Speech recognition experiments show around 18\% reduction of word error rate on the Wall Street Journal task when comparing models trained on the same amount of data, and around 5\% on the much harder NIST RT05 task, even when the backoff model is trained on much more data than the RNN LM. We provide ample empirical evidence to suggest that connectionist language models are superior to standard n-gram techniques, except their high computational (training) complexity.}
}
@inproceedings{
Melis2020Mogrifier,
title={Mogrifier LSTM},
author={Gábor Melis and Tomáš Kočiský and Phil Blunsom},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=SJe5P6EYvS}
}
@article{LSTM,
author = {Hochreiter, Sepp and Schmidhuber, Jürgen},
year = {1997},
month = {12},
pages = {1735-80},
title = {Long Short-term Memory},
volume = {9},
journal = {Neural computation},
doi = {10.1162/neco.1997.9.8.1735}
}
@misc{GRU,
  doi = {10.48550/ARXIV.1412.3555},
  url = {https://arxiv.org/abs/1412.3555},
  author = {Chung, Junyoung and Gulcehre, Caglar and Cho, KyungHyun and Bengio, Yoshua},
  keywords = {Neural and Evolutionary Computing (cs.NE), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling},
  publisher = {arXiv},
  year = {2014},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
@misc{https://doi.org/10.48550/arxiv.1706.03762,
  doi = {10.48550/ARXIV.1706.03762},
  url = {https://arxiv.org/abs/1706.03762},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
  keywords = {Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Attention Is All You Need},
  publisher = {arXiv},
  year = {2017},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
@misc{https://doi.org/10.48550/arxiv.1708.02182,
  doi = {10.48550/ARXIV.1708.02182},
  url = {https://arxiv.org/abs/1708.02182},
  author = {Merity, Stephen and Keskar, Nitish Shirish and Socher, Richard},
  keywords = {Computation and Language (cs.CL), Machine Learning (cs.LG), Neural and Evolutionary Computing (cs.NE), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Regularizing and Optimizing LSTM Language Models},
  publisher = {arXiv},
  year = {2017},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
@misc{https://doi.org/10.48550/arxiv.1705.08209,
  doi = {10.48550/ARXIV.1705.08209},
  url = {https://arxiv.org/abs/1705.08209},
  author = {Tallec, Corentin and Ollivier, Yann},
  keywords = {Neural and Evolutionary Computing (cs.NE), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Unbiasing Truncated Backpropagation Through Time},
  publisher = {arXiv},
  year = {2017},
  copyright = {arXiv.org perpetual, non-exclusive license}
}